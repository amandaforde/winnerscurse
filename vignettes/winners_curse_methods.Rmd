---
title: "Methods for use with discovery GWAS"
output: 
  rmarkdown::html_vignette:
    toc: yes
vignette: >
  %\VignetteIndexEntry{Methods for use with discovery GWAS}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(winnerscurse)
```


In order to demonstrate how this package can be used to obtain new adjusted $\hat\beta$ estimates, we first create a toy data set and subsequently, illustrate how a user could engage with each of the package's functions using this data set. The methods currently available for implementation are: 

1. Conditional Likelihood methods - [Ghosh *et al.* (2008)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2665019/)
2. Empirical Bayes method - [Ferguson *et al.* (2013)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4048064/) 
3. FDR Inverse Quantile Transformation method - [Bigdeli *et al.* (2016)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5013908/) 
4. Bootstrap method - adapted from [Faye *et al.* (2011)](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4228)


An important feature which distinguishes these four methods is detailed in the table below: 


+----------------------------------------------------+----------------------------------------------+
| Adjusts $\beta$ estimate of *only* SNPs with       | Adjusts $\beta$ estimate of *all* SNPs       |
| $p$-values less than specified threshold, $\alpha$ |                                              |
+====================================================+==============================================+
| - Conditional Likelihood methods                   | - Empirical Bayes method                     |
|                                                    | - FDR Inverse Quantile Transformation method |
|                                                    | - Bootstrap method                           |
+----------------------------------------------------+----------------------------------------------+



 


### Creating a toy data set

- We wish to generate summary statistics for 1 million SNPs, in which there exists a polygenic background of 10,000 SNPs while all others have no effects.

- We specify:
  1. the total number of SNPs
  2. the number of SNPs truly associated with the trait
  3. the number of samples
  4. the minor allele frequency of each SNP 
  5. the variance explained in the trait by all SNPs, $h^2$ 


- With these specifications, we can obtain quite realistic summary statistics as shown below.

- The summary statistics have been arranged here in a suitable way for each method - in the form of a **data frame with columns `rsid`, `beta` and `se`.** 

```{r}
set.seed(1998)

n_snps <- 10^6
n_samples <- 30000
effect_snps <- 0.01*n_snps
maf <- runif(n_snps,0.01,0.5)
true_beta <- rnorm(effect_snps,0,1)
h2 <- 0.7  # variance explained by effect SNPs
var_y <- sum(2*maf[1:effect_snps]*(1-maf[1:effect_snps])*true_beta^2)/h2
true_beta <- true_beta/sqrt(var_y) # scaling to represent a phenotype with variance 1
true_beta <- c(true_beta, rep(0,n_snps-effect_snps))
se <- sqrt((1 - 2*maf*(1-maf)*true_beta^2)/(2*(n_samples-2)*maf*(1-maf)))

summary_stats <- data.frame(rsid=seq(1,n_snps),beta=rnorm(n=n_snps,mean=true_beta,sd=se),se=se)
head(summary_stats)
```

### Method 1: Conditional Likelihood

- The function `conditional_likelihood` requires a data frame, in the form described above, and a value for `alpha`, the significance threshold used in the GWAS. Note that all columns of the data frame must contain numerical values and each row must represent a unique SNP, identified by `rsid`.  

- As the conditional likelihood methods have been designed to be only used for SNPs which are deemed significant, the data frame returned contains only SNPs that have $p$-values below the inputted genome-wide significance threshold value, `alpha`.

- **Note:**  In order for this function to output an appropriate value for the
second form of the adjusted estimate, namely `beta.cl2`,
for each significant SNP, the absolute value of the largest $z$-statistic
in the data set must be less than 150.

- If no SNPs are detected as significant, the function returns a warning message: `WARNING: There are no significant SNPs at this threshold`. 

- The returned data frame has SNPs ordered based on their $p$-values from smallest to largest, or equivalently, in descending order of $\mid z \mid$ in which $z$ is the estimated value for $\beta$ divided by its standard error. 

- We implement the function on our toy data set as follows, choosing a significance threshold of `5e-8`:

```{r}
out_CL <- conditional_likelihood(summary_data = summary_stats, alpha = 5e-8) 
head(out_CL)
```

- Three columns have been added to the right of the inputted data frame: each represents a correction method suggested in [Ghosh *et al.* (2008)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2665019/). The first, `beta.cl1`, is referred to as the conditional MLE while the second, `beta.cl2`, is the mean of the normalized conditional likelihood. The third, `beta.cl3` is merely the average of the first two, known as the compromise estimator. 

- Ghosh *et al.* (2008) noted that for instances in which the true $\beta$ value is close to zero, `beta.cl2` often has greater mean squared error than `beta.cl1` but for true $\beta$ values further from zero, `beta.cl2` performs better. Thus, it was suggested that `beta.cl3` be used to combine the strengths of these two estimators. However, this function, `conditional_likelihood`, outputs values for all three estimators in order to allow the user to make their own decision on which they believe to be the most appropriate. 


### Method 2: Empirical Bayes 

- The function `empirical_bayes` implements the Empirical Bayes method for correcting for Winner's Curse, detailed in [Ferguson *et al.* (2013)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4048064/), with a slight modification. 

- The function has two arguments with the first being `summary_data`, the data frame containing `rsid`, `beta` and `se` columns. Again, all columns of the data frame must contain numerical values and each row must represent a unique SNP, identified by `rsid`. In addition, the function requires that the data frame must contain at least 50 rows corresponding to 50 unique SNPs. This requirement is included as the Empirical Bayes method performs poorly when only data of a small number of SNPs is available. The second argument, `AIC`, is a logical parameter which allows the user to choose if they wish to use an AIC approach to determine an appropriate value for the degrees of freedom. The current default setting is `AIC=TRUE`. If `AIC=FALSE`, the degrees of freedom is set to 7. Using `AIC=FALSE` is the recommended approach if the user is working with a real data set, unless they are certain that there is a minimal degree of LD in their array.

- It returns the above described data frame but with a fourth column, `beta_EB` in which the adjusted estimates of this procedure have been added. 

- As the Empirical Bayes method makes adjustments to all SNPs, not only those that have been considered significant, this data frame contains all SNPs.  

- **Note:** The conditional likelihood methods adjust each statistic one at a time, and so summary statistics of one individual SNP can easily be inputted into the `conditional_likelihood` function. However, the Empirical Bayes method requires many SNPs as the more information given to the function, the more accurate it will be at modelling the distribution and thus, making adjustments. Thus, as mentioned above, `summary_data` must contain information related to more than 50 SNPs.


- Below is a demonstration of using `empirical_bayes` with our toy data set with the default setting for `AIC`:

```{r, warning=FALSE}
out_EB <- empirical_bayes(summary_data = summary_stats)
head(out_EB)
```


- Unfortunately, the Empirical Bayes estimator described by Ferguson *et al.* (2013) is known to perform poorly in the extreme tails of the distribution. Therefore, it is quite possible that a lack of adjustment for the $\beta$ values of SNPs with the most extreme $z$-statistics could be witnessed with this method. A somewhat ad hoc approach to overcome this issue of combining the Empirical Bayes and the conditional likelihood methods was suggested by Ferguson *et al.* (2013). 

- In order to ensure that shrinkage does occur for the $\beta$ values of these extreme SNPs, it was decided that the following modification would be added to the `empirical_bayes` function detailed here. The basis function of the natural cubic spline has been altered so that the boundary knots are no longer the most extreme $z$-values. Instead, the lower boundary knot is defined as the $10^{\text{th}}$ $z$-statistic when the $z$-statistics lie in increasing order while the upper boundary knot is the $10^{\text{th}}$ $z$-statistic when the $z$-statistics have been arranged in decreasing order. The natural cubic spline is then merely linear beyond these boundary knots. This assists in fixing the 'tails' issue discussed above. We see that the reduction of the estimated $\beta$ values for all of the top 6 most significant SNPs has occurred. 



### Method 3: FDR Inverse Quantile Transformation 

- The function `FDR_IQT` implements the winner's curse adjustment method detailed in [Bigdeli *et al.* (2016)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5013908/). 

- Similar to the approaches above, the function requires a data frame with three columns `rsid`, `beta` and `se`,  all columns of the data frame must contain numerical values and each row must represent a unique SNP, identified by `rsid`. 

- It also has an argument `min_pval`, for which the default setting is `1e-15`. This is included in order to avoid zero $p$-values which can prove problematic for the function when evaluating `qnorm()`. Furthermore, due to the nature of winner's curse, it is in fact rare that observations with $\mid z \mid > 8$ are biased. 

- The function outputs a data frame similar to that inputted with an additional column containing the adjusted estimate, `beta_FIQT`, and again, the SNPs have been reordered according to their individual $z$-statistics. 

```{r}
out_FIQT <- FDR_IQT(summary_data = summary_stats)
head(out_FIQT)

```


### Method 4: Bootstrap 

- Inspired by the winner's curse adjustment method detailed in [Faye *et al.* (2011)](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4228), the function `BR_ss` implements a computationally efficient bootstrap method which is suitable for use with summary statistics. 

- `BR_ss` takes a data frame `summary_data` with three columns: `rsid`, `beta`, `se`, and returns the inputted data frame along with the adjusted estimate for $\beta$, `beta_BR_ss`. Note that all columns of the data frame, `summary data` must contain numerical values, each row must represent a unique SNP, identified by `rsid` and the function requires that there must be at least 5 unique SNPs so that the smoothing spline can be implemented successfully.  The function also has a logical parameter `seed_opt` which can be set to `TRUE` by the user to permit reproducibility. Its default setting is `seed_opt=FALSE`. As this method involves bootstrap implementation, the use of a seed can allow the user to obtain the exact same results for `beta_BR_ss` when running the function many times on the same dataset. The parameter `seed` provides the user with an option to set their desired value for the seed when using `seed_opt=TRUE`. The default for `seed` is the arbitrary value of `1998`. 

$~$

**Method description:**

- First, the $N$ SNPs are arranged according to their naive $z$-statistics, $\frac{\hat\beta}{\text{se}(\hat\beta)}$, in descending order and given rank $k$. Thus, the SNP with the largest positive original $z$-statistic is given rank $k=1$ while the SNP with the largest negative original $z$-statistic receives rank $k=N$. 

- Following this, a parametric bootstrap is performed in which a value $\hat\beta^{\text{b}}_{(k)}$ is simulated for SNP $k$ from the distribution: 
$$\hat\beta^{\text{b}}_{(k)} \sim N(\hat\beta_{(k)}, \text{se}(\hat\beta_{(k)})).$$ Upon obtaining $\hat\beta^{\text{b}}$, SNPs undergo a second ordering in which they are arranged based on $z^{\text{b}}$-statistics and receive a rank $A(k)$ accordingly. The $z^{\text{b}}_{(k)}$-statistic of SNP $k$ is equal to $\frac{\hat\beta^{\text{b}}_{(k)}}{\text{se}(\hat\beta_{(k)})}$. 

- An estimate for the bias correction value of SNP $k$ is given as:
$$\text{bias}_{(k)} = \frac{\hat\beta^{\text{b}}_{A(k)} - \hat\beta^{\text{oob}}_{A(k)}}{\text{se}(\hat\beta_{A(k)})} = \frac{\hat\beta^{\text{b}}_{A(k)} - \hat\beta_{A(k)}}{\text{se}(\hat\beta_{A(k)})}, $$in which $\hat\beta^{\text{b}}_{A(k)}$ is the bootstrap value of the SNP ranked in position $k$ in the second ordering, $\hat\beta^{\text{oob}}_{A(k)} = \hat\beta_{A(k)}$ is that same SNP's naive $\beta$ estimate and $\text{se}(\hat\beta_{A(k)})$ it's standard error. 

- Next, a cubic smoothing spline is fitted to the data using `stats::smooth.spline` in which $z_{(k)}$-statistics are considered as the inputs and $\text{bias}_{(k)}$, their corresponding outputs. The predicted values from this process provides $\text{bias}^{*}_{(k)}$ for each SNP. Using $\text{bias}^{*}_{(k)}$ instead of $\text{bias}_{(k)}$ results in a faster approach with increased accuracy as only one bootstrap iteration for each SNP is sufficient for competitive performance. 

- Finally, the new estimate for $\beta$ for SNP $k$ is defined as follows:
$$\hat\beta_{(k)}^{*} = \hat\beta_{(k)} - \text{se}(\hat\beta_{(k)}) \cdot  \text{bias}^{*}_{(k)}.$$


```{r}
out_BR_ss <- BR_ss(summary_data = summary_stats, seed=2020)
head(out_BR_ss)
```





### Comparing Results

As we have simulated our data set, we have the ability to quantify the amount of bias present in the original naive $\beta$ estimates and also, in our adjusted estimates for each method. We can use measures such as the sum of squared differences (`sq_diff`) and mean of absolute differences (`mean_abs_diff`) to assess this bias. Furthermore, we can also simply obtain the fraction of SNPs which are now *less* biased after adjustment (`frac_less_bias`). These three evaluation metrics can be be mathematically defined as follows, in which there are $n$ significant SNPs: 

- `sq_diff` $= \sum_{i=1}^n (\beta_i - \hat\beta_{\text{adj},i})^2$
- `mean_abs_diff` $= \frac{1}{n} \sum_{i=1}^n |\beta_i - \hat\beta_{\text{adj},i}|$ 
- `frac_less_bias` $= \frac{1}{n} \sum_{i=1}^n \text{I} \{ |\beta_i - \hat\beta_{i}| \gt |\beta_i - \hat\beta_{\text{adj},i}| \}$

First, we take a look at the conditional likelihood method as follows, in which only SNPs that are originally deemed significant are included: 

```{r}
sq_diff_1 <- data.frame(naive = sum((true_beta[out_CL$rsid] - out_CL$beta)^2), beta.cl1 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl1)^2),  beta.cl2 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl2)^2),  beta.cl3 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl3)^2))
sq_diff_1

mean_abs_diff_1 <- data.frame(naive = mean(abs(true_beta[out_CL$rsid] - out_CL$beta)), beta.cl1 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl1)),  beta.cl2 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl2)),  beta.cl3 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl3)))
mean_abs_diff_1

frac_less_bias_1 <- data.frame(beta.cl1 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl1)))/nrow(out_CL), beta.cl2 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl2)))/nrow(out_CL), beta.cl3 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl3)))/nrow(out_CL))
frac_less_bias_1
```

For the first two quantities, the values for all three conditional likelihood methods are less than that of the naive estimate and we find that at least `r round(frac_less_bias_1[1,1],2)*100`% of the significant SNPs are now less biased.


Next, we investigate the other three methods described above which take into account all SNPs, not just those with $p$-values less than a specified threshold. Thus, when computing the values below, $n$ is now equal to the total number of SNPs, i.e. $n = 1,000,000$.

```{r}
sq_diff_2 <- data.frame(naive = sum((true_beta[out_EB$rsid] - out_EB$beta)^2), beta_EB = sum((true_beta[out_EB$rsid] - out_EB$beta_EB)^2), beta_FIQT = sum((true_beta[out_FIQT$rsid] - out_FIQT$beta_FIQT)^2), beta_BR_ss = sum((true_beta[out_BR_ss$rsid] - out_BR_ss$beta_BR_ss)^2))
sq_diff_2

mean_abs_diff_2 <- data.frame(naive = mean(abs(true_beta[out_EB$rsid] - out_EB$beta)), beta_EB = mean(abs(true_beta[out_EB$rsid] - out_EB$beta_EB)), beta_FIQT = mean(abs(true_beta[out_FIQT$rsid] - out_FIQT$beta_FIQT)), beta_BR_ss = mean(abs(true_beta[out_BR_ss$rsid] - out_BR_ss$beta_BR_ss)))
mean_abs_diff_2

frac_less_bias_2 <- data.frame(beta_EB = (sum(abs(true_beta[out_EB$rsid] - out_EB$beta) > abs(true_beta[out_EB$rsid] - out_EB$beta_EB)))/nrow(out_EB), beta_FIQT = (sum(abs(true_beta[out_FIQT$rsid] - out_FIQT$beta) > abs(true_beta[out_FIQT$rsid] - out_FIQT$beta_FIQT)))/nrow(out_FIQT), beta_BR_ss = (sum(abs(true_beta[out_BR_ss$rsid] - out_BR_ss$beta) > abs(true_beta[out_BR_ss$rsid] - out_BR_ss$beta_BR_ss)))/nrow(out_BR_ss))
frac_less_bias_2

```
Again, we see that in the top two cases, the value associated with the naive estimate is greatest. This assures us that the new adjusted estimates provided by each method are indeed less biased than the original $\beta$ estimate. In fact, for each method, at least `r round(min(frac_less_bias_2[1,]),2)*100`% of the association estimates of all SNPs are now less biased. 


Finally, we can compare the performance of all methods for the SNPs with raw $p$-values less than `5e-8`.
```{r}
out_EB_sig <- out_EB[2*(1-pnorm(abs(out_EB$beta/out_EB$se))) < 5e-8,]
out_FIQT_sig <- out_FIQT[2*(1-pnorm(abs(out_FIQT$beta/out_FIQT$se))) < 5e-8,]
out_BR_ss_sig <- out_BR_ss[2*(1-pnorm(abs(out_BR_ss$beta/out_BR_ss$se))) < 5e-8,]

sq_diff_3 <- data.frame(naive = sum((true_beta[out_CL$rsid] - out_CL$beta)^2), beta.cl1 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl1)^2),  beta.cl2 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl2)^2),  beta.cl3 = sum((true_beta[out_CL$rsid] - out_CL$beta.cl3)^2), beta_EB = sum((true_beta[out_EB_sig$rsid] - out_EB_sig$beta_EB)^2), beta_FIQT = sum((true_beta[out_FIQT_sig$rsid] - out_FIQT_sig$beta_FIQT)^2), beta_BR_ss = sum((true_beta[out_BR_ss_sig$rsid] - out_BR_ss_sig$beta_BR_ss)^2))
sq_diff_3

mean_abs_diff_3 <- data.frame(naive = mean(abs(true_beta[out_CL$rsid] - out_CL$beta)), beta.cl1 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl1)),  beta.cl2 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl2)),  beta.cl3 = mean(abs(true_beta[out_CL$rsid] - out_CL$beta.cl3)), beta_EB = mean(abs(true_beta[out_EB_sig$rsid] - out_EB_sig$beta_EB)), beta_FIQT = mean(abs(true_beta[out_FIQT_sig$rsid] - out_FIQT_sig$beta_FIQT)), beta_BR_ss = mean(abs(true_beta[out_BR_ss_sig$rsid] - out_BR_ss_sig$beta_BR_ss)))
mean_abs_diff_3

frac_less_bias_3 <- data.frame(beta.cl1 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl1)))/nrow(out_CL), beta.cl2 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl2)))/nrow(out_CL), beta.cl3 = (sum(abs(true_beta[out_CL$rsid] - out_CL$beta) > abs(true_beta[out_CL$rsid] - out_CL$beta.cl3)))/nrow(out_CL), beta_EB = (sum(abs(true_beta[out_EB_sig$rsid] - out_EB_sig$beta) > abs(true_beta[out_EB_sig$rsid] - out_EB_sig$beta_EB)))/nrow(out_EB_sig), beta_FIQT = (sum(abs(true_beta[out_FIQT_sig$rsid] - out_FIQT_sig$beta) > abs(true_beta[out_FIQT_sig$rsid] - out_FIQT_sig$beta_FIQT)))/nrow(out_FIQT_sig), beta_BR_ss = (sum(abs(true_beta[out_BR_ss_sig$rsid] - out_BR_ss_sig$beta) > abs(true_beta[out_BR_ss_sig$rsid] - out_BR_ss_sig$beta_BR_ss)))/nrow(out_BR_ss_sig))
frac_less_bias_3

```


$~$
$~$

In addition, we can gain a visual insight into the adjustments made by these functions by plotting the adjusted *absolute* values along with the naive estimates and the true *absolute* $\beta$ values of SNPs which are originally deemed as significant, i.e. those with raw $p$-values less than `5e-8`, as follows: 

```{r, fig.height=4.5,fig.width=6.5, warning=FALSE}
library("RColorBrewer")
col <- brewer.pal(8,"Dark2")
  
plot(density(abs(out_EB_sig$beta)),ylim=c(0,80),xlim=c(-0.01,0.09),main="Comparing Winner's Curse Methods",col=col[1],lwd=2)
lines(density(abs(true_beta[out_CL$rsid])),col=col[2],lwd=2)
lines(density(abs(out_FIQT_sig$beta_FIQT)),col=col[3],lwd=2)
lines(density(abs(out_CL$beta.cl1)),col=col[4],lwd=2)
lines(density(abs(out_CL$beta.cl2)),col=col[5],lwd=2)
lines(density(abs(out_CL$beta.cl3)),col=col[6],lwd=2)
lines(density(abs(out_EB_sig$beta_EB)),col=col[7],lwd=2)
lines(density(abs(out_BR_ss_sig$beta_BR_ss)),col=col[8],lwd=2)
legend(-0.008, 77.5, legend=c("beta_naive", "true_beta","beta_FIQT","beta.cl1","beta.cl2","beta.cl3","beta_EB", "beta_BR_ss"),
       col=col,lty=1,lwd=2)

```



$~$
$~$








